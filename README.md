# DBT-CLIP: Breast Cancer Classification via Transfer Learning

A robust, leak-safe machine learning pipeline for classifying breast cancer screening images (Digital Breast Tomosynthesis) using CLIP embeddings and an MLP classifier.

## ğŸ¯ Overview

This project implements a **two-stage transfer learning approach** for multi-class breast cancer classification:
1. **Feature Extraction**: Uses pre-trained CLIP (ViT-B/32) as a frozen feature extractor
2. **Classification**: Trains a lightweight MLP on extracted 512-dimensional embeddings

### Key Features

âœ… **Fully Reproducible** - Auto-installs dependencies and downloads dataset from Kaggle  
âœ… **Leak-Safe Design** - Data splitting performed BEFORE any augmentation or resampling  
âœ… **Imbalance-Aware** - Combines SMOTETomek, Focal Loss, and ENS class weights  
âœ… **Comprehensive Evaluation** - Generates confusion matrices, ROC/PR curves, and per-class metrics  
âœ… **Professional Documentation** - Exports results as JPG figures and Word documents  

---

## ğŸ“Š Dataset

**Source**: [Breast Cancer Screening DBT Dataset](https://www.kaggle.com/datasets/gabrielcarvalho11/breast-cancer-screening-dbt)

**Classes** (4):
- Benign
- Actionable
- Cancer
- Normal

The dataset is automatically downloaded via `kagglehub` when you run the notebook.

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- CUDA-capable GPU (optional, but recommended)
- Kaggle account (for dataset download)

### Installation & Running

The notebook handles all dependencies automatically! Just run:

```bash
# Clone the repository
git clone https://github.com/phat-hee/dbt-clip-breast-cancer.git
cd dbt-clip-breast-cancer

# Run the notebook
jupyter notebook breast_cancer_dbt_clip_pipeline.ipynb
```

All required packages will be installed automatically on first run.

---

## ğŸ—ï¸ Architecture

### Pipeline Overview

```
Raw Images â†’ [CLIP Encoder (frozen)] â†’ 512-d Embeddings â†’ [MLP (trained)] â†’ 4 Classes
              â””â”€ ViT-B/32 pre-trained                      â””â”€ Focal Loss + ENS weights
```

### Model Components

1. **CLIP (ViT-B/32)** - Pre-trained vision encoder (frozen)
   - Extracts 512-dimensional feature vectors
   - No training/fine-tuning performed

2. **MLP Classifier** - 2-layer feedforward network
   - Input: 512-d CLIP features
   - Hidden layers: 256 â†’ 128
   - Output: 4 classes
   - Regularization: BatchNorm + Dropout (0.5)

3. **Loss Function** - Focal Loss with Î± weights
   - Handles class imbalance
   - Focuses learning on hard examples
   - Î± computed via Effective Number of Samples (ENS)

---

## ğŸ“ˆ Methodology

### 1. Data Splitting (Leak-Safe)
```
All Images (100%)
    â†“
Train (64%) / Temp (36%)
    â†“
Train (64%) / Val (16%) / Test (20%)
```
- **Stratified splits** maintain class distributions
- Splitting done **BEFORE** any preprocessing

### 2. Imbalance Handling (Train Only)
- **SMOTETomek**: Synthetic minority oversampling + Tomek link removal
- **Focal Loss**: Î³=2.0 focuses on hard examples
- **ENS Weights**: Class-wise Î± weights based on effective samples

### 3. Augmentation (Train Only, Minority Classes)
- Horizontal/Vertical flips
- Random 90Â° rotation
- Brightness/Contrast adjustment
- Shift/Scale/Rotate transforms

### 4. Training
- Optimizer: Adam (lr=1e-3, weight_decay=1e-5)
- Scheduler: CosineAnnealingLR
- Epochs: 30
- Batch size: 32
- Best model selected by validation loss

---

## ğŸ“ Project Structure

```
dbt-clip-breast-cancer/
â”œâ”€â”€ breast_cancer_dbt_clip_pipeline.ipynb   # Main notebook
â”œâ”€â”€ README.md                                # This file
â”œâ”€â”€ data/                                    # Dataset (auto-downloaded)
â”‚   â””â”€â”€ Breast-Cancer-Screening-DBT/
â”‚       â”œâ”€â”€ Benign/
â”‚       â”œâ”€â”€ Actionable/
â”‚       â”œâ”€â”€ Cancer/
â”‚       â””â”€â”€ Normal/
â””â”€â”€ results/                                 # All outputs
    â”œâ”€â”€ Figure_Class_Distribution_All.jpg
    â”œâ”€â”€ Figure_Class_Distribution_All.docx
    â”œâ”€â”€ Figure_Training_Loss.jpg
    â”œâ”€â”€ Figure_Validation_Confusion_Matrix.jpg
    â”œâ”€â”€ Figure_Test_ROC_PR.jpg
    â”œâ”€â”€ Table_Test_Overall_Metrics.docx
    â”œâ”€â”€ Table_Test_PerClass_Metrics.docx
    â””â”€â”€ Summary_Experiment.docx
```

---

## ğŸ“Š Results

The pipeline generates comprehensive evaluation metrics:

### Overall Metrics
- Accuracy
- Balanced Accuracy
- Macro F1 Score
- Macro Precision/Recall
- Macro AUC-ROC

### Per-Class Metrics
- Precision
- Recall
- F1 Score
- Specificity
- AUC-ROC

### Visualizations
- Class distribution plots
- Training/validation loss curves
- Normalized confusion matrices
- ROC curves (one-vs-rest)
- Precision-Recall curves

All outputs are saved as:
- **JPG images** (300 DPI, publication-ready)
- **Word documents** (.docx) with captions and descriptions

---

## ğŸ”¬ Technical Details

### Why This Approach?

**Transfer Learning Benefits:**
- âœ… Leverages CLIP's knowledge from 400M image-text pairs
- âœ… Reduces training time (minutes vs. hours)
- âœ… Works well with limited medical imaging data
- âœ… Lower computational requirements

**Frozen vs. Fine-tuning:**
- This implementation uses **frozen CLIP** (feature extraction only)
- Fine-tuning CLIP end-to-end could potentially improve results, but requires:
  - More GPU memory
  - Longer training time
  - Risk of overfitting on small datasets

### Reproducibility

- Fixed random seeds (RANDOM_STATE=42)
- Deterministic operations where possible
- Complete environment captured via auto-installation
- Dataset version pinned (v1)

---

## ğŸ› ï¸ Dependencies

Automatically installed packages:
- `torch`, `torchvision` - Deep learning framework
- `clip-anytorch` - OpenAI CLIP model
- `scikit-learn` - ML utilities and metrics
- `imbalanced-learn` - SMOTETomek resampling
- `albumentations` - Image augmentation
- `pandas`, `numpy` - Data manipulation
- `matplotlib`, `seaborn` - Visualization
- `python-docx` - Word document export
- `kagglehub` - Dataset download
- `opencv-python-headless` - Image processing

---

## ğŸ“ Usage Examples

### Running the Full Pipeline
```python
# Just run all cells in the notebook!
# Everything is automated from installation to results export
```

### Customizing Parameters
```python
# In the configuration cell, modify:
RANDOM_STATE = 42        # Change for different splits
EPOCHS = 30              # Training epochs
BATCH_SIZE = 32          # Batch size
LEARNING_RATE = 1e-3     # Initial learning rate
```

### Using Custom Dataset
```python
# Replace the Kaggle download section with:
DATASET_DIR = Path("/path/to/your/dataset")
# Ensure folder structure: DATASET_DIR/ClassName/images.jpg
```

---

## ğŸ“ Citation

If you use this code in your research, please cite:

```bibtex
@software{dbt_clip_2024,
  title={DBT-CLIP: Breast Cancer Classification via Transfer Learning},
  author={N. Alipour, M. Faramarzi, M. Gholami, M. Fathi , N. Deravi},
  year={2024},
  url={https://github.com/phat-hee/dbt-clip-breast-cancer}
}
```

**Dataset Citation:**
```bibtex
@dataset{carvalho2024dbt,
  title={Breast Cancer Screening DBT Dataset},
  author={Carvalho, Gabriel},
  year={2024},
  publisher={Kaggle},
  url={https://www.kaggle.com/datasets/gabrielcarvalho11/breast-cancer-screening-dbt}
}
```

---

## ğŸ¤ Contributing

Contributions are welcome! Areas for improvement:
- [ ] Fine-tuning CLIP end-to-end
- [ ] Experimenting with other CLIP variants (ViT-L/14, ResNet-50)
- [ ] Ensemble methods
- [ ] Grad-CAM visualization
- [ ] Cross-validation
- [ ] Hyperparameter optimization

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## âš ï¸ Disclaimer

This is a research tool and **NOT approved for clinical use**. Always consult healthcare professionals for medical diagnosis and treatment decisions.

---

## ğŸ“§ Contact

- **Author**: Mohammad Fathi
- **Email**: mohammad.s.fathi98@gmail.com
- **GitHub**: [@phat-hee](https://github.com/phat-hee)
- **Project Link**: [https://github.com/phat-hee/dbt-clip-breast-cancer](https://github.com/yourusername/dbt-clip-breast-cancer)

---

## ğŸ™ Acknowledgments

- OpenAI for the CLIP model
- Kaggle community for the dataset
- PyTorch team for the deep learning framework


